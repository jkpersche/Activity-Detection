{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can't figure out how to import Tslearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/tslearn/bases/bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "#import sklearn\n",
    "import tslearn\n",
    "import math \n",
    "import os\n",
    "import scipy.stats as stats\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "from statistics import mode\n",
 
    "from scipy import signal\n",
    "from scipy.signal import find_peaks, peak_prominences\n",
    "\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.metrics import dtw\n",
    "from tslearn.utils import to_time_series_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import, Reorder & Label CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/juliapersche/Desktop/darpa_datascience folder/A_DeviceMotion_data/User_1'\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0,2,4,5,8,3,6,10,9,11,1,7,12,13,14]\n",
    "data = [csv_files[i] for i in indices]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = []\n",
    "activities = ['jog', 'jog','dws','dws','dws', 'wlk','wlk', 'wlk','std','std','ups','ups','ups','sit','sit']\n",
    "trials = [16,9,11,1,2,8,15,7,14,6,12,4,3,5,13]\n",
    "\n",
    "counter = 0\n",
    "for f in data:\n",
    "       # read the csv file\n",
    "        k = pd.read_csv(f).rename(columns={'Unnamed: 0': 'time'})\n",
    "        #Label\n",
    "        k['activity'] = counter\n",
    "        k['trial'] = trials[counter]\n",
    "        list_of_dfs.append(k)\n",
    "        counter += 1\n",
    "        \n",
    "\n",
    "df = pd.concat(list_of_dfs).set_index('time')\n",
    "df = df.drop(['attitude.roll', 'attitude.pitch', 'attitude.yaw', 'gravity.x', 'gravity.y', 'gravity.z'], axis=1)\n",
    "df = df.rename(columns={'rotationRate.x': 'gyro_x', 'rotationRate.y': 'gyro_y', 'rotationRate.z': 'gyro_z'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Accel Energy & Resample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mx_norm\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39muserAcceleration.x\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39muserAcceleration.x\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean()) \u001b[39m/\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39muserAcceleration.x\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39muserAcceleration.x\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmin())\n\u001b[1;32m      2\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39my_norm\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39muserAcceleration.y\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39muserAcceleration.y\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean()) \u001b[39m/\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39muserAcceleration.y\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39muserAcceleration.y\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmin())\n\u001b[1;32m      3\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mz_norm\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39muserAcceleration.z\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39muserAcceleration.z\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean()) \u001b[39m/\u001b[39m (df[\u001b[39m'\u001b[39m\u001b[39muserAcceleration.z\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmax() \u001b[39m-\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39muserAcceleration.z\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmin())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['x_norm'] = (df['userAcceleration.x'] - df['userAcceleration.x'].mean()) / (df['userAcceleration.x'].max() - df['userAcceleration.x'].min())\n",
    "df['y_norm'] = (df['userAcceleration.y'] - df['userAcceleration.y'].mean()) / (df['userAcceleration.y'].max() - df['userAcceleration.y'].min())\n",
    "df['z_norm'] = (df['userAcceleration.z'] - df['userAcceleration.z'].mean()) / (df['userAcceleration.z'].max() - df['userAcceleration.z'].min())\n",
    "\n",
    "df['energy'] = (abs(df['x_norm']**2 + df['y_norm']**2 + df['z_norm']**2))**.5\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resampling (from 50 to 20 Hz) --> unsure why resampled from 50 to 20 Hz\n",
    "df['time'] = np.arange(0, len(df)*20, 20)\n",
    "df['time'] = pd.to_timedelta(df['time'], unit='ms')\n",
    "df = df.set_index('time')\n",
    "df_resample = df.resample('50ms').mean()\n",
    "df['time'] = df_resample.set_index\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Energy of Different Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 1, sharex ='col')\n",
    "\n",
    "axs[0].plot(x, df.loc[df['activity'] == 1]['energy'][0:200])\n",
    "axs[0].set_ylabel('downstairs \\n energy')\n",
    "axs[1].plot(x, df.loc[df['activity'] == 0]['energy'][0:200])\n",
    "axs[1].set_ylabel('jog \\n energy')\n",
    "axs[2].plot(x, df.loc[df['activity'] == 5]['energy'][0:200])\n",
    "axs[2].set_ylabel('sit \\n energy')\n",
    "axs[3].plot(x, df.loc[df['activity'] == 3]['energy'][0:200])\n",
    "axs[3].set_ylabel('standing \\n energy')\n",
    "axs[4].plot(x, df.loc[df['activity'] == 4]['energy'][0:200])\n",
    "axs[4].set_ylabel('upstairs \\n energy')\n",
    "axs[5].plot(x, df.loc[df['activity'] == 2]['energy'][0:200])\n",
    "axs[5].set_ylabel('walking \\n energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting energy computed for each trial into 10 second windos with 5 second overlap\n",
    "energy_windows = sliding_window_view(stats.zscore((df['energy']).to_numpy()), 200)[::150, :]\n",
    "\n",
    "#Splitting up corresponding labels\n",
    "activity_windows = sliding_window_view((df['activity']), 200)[::150, :]\n",
    "\n",
    "energy_windows.shape\n",
    "print(energy_windows)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dictionary with keys for each activity and corresponding windows \n",
    "### This dictionary will serve as 'ground truth' when determining the accuracy of the kmeans clustering assignment for each unlabeled energy window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_labels = [statistics.mode(x) for x in activity_windows]\n",
    "activity_splits = {}\n",
    "for i, act in enumerate(activity_labels):\n",
    "    activity = activities[act]\n",
    "    if activity_splits.get(activity) == None:\n",
    "        activity_splits[activity] = []\n",
    "    activity_splits[activity].append(i)\n",
    "\n",
    "print(activity_splits)\n",
    "\n",
    "#Printing number of activities in each key \n",
    "for key, value in activity_splits.items():\n",
    "    #print value\n",
    "    print(key, len([item for item in value if item]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remap assigned labels to actual activity labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jog 0 --> 1 \n",
    "#dws 1 --> 0 \n",
    "#wlk 2 --> 2\n",
    "#std 3 --> 5\n",
    "#ups 4 --> 0 \n",
    "#sit 5 --> 5 \n",
    "\n",
    "for key, value in activity_splits.items():\n",
    "    if key == 'jog':\n",
    "          jog_label = np.full(len([item for item in value if item])+1, 1, dtype=int)\n",
    "    if key == 'dws':\n",
    "           dws_label = np.full(len([item for item in value if item]), 0, dtype=int)\n",
    "    if key == 'wlk':\n",
    "         wlk_label = np.full(len([item for item in value if item]), 2, dtype=int)\n",
    "    if key == 'std':\n",
    "         std_label = np.full(len([item for item in value if item]), 5, dtype=int)\n",
    "    if key == 'ups':\n",
    "         ups_label = np.full(len([item for item in value if item]), 0, dtype=int)\n",
    "    if key == 'sit':\n",
    "         sit_label = np.full(len([item for item in value if item]), 5, dtype=int)\n",
    "    \n",
    "labels = np.concatenate((jog_label,dws_label,wlk_label,std_label,ups_label,sit_label))\n",
    "labels.shape\n",
    "print(len(labels))\n",
    "\n",
    "print(np.sum(labels==0))\n",
    "print(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Createte Kmeans model with unlabeled Energy Windows\n",
    "### Since we are working with Time Series Data, we expect to see a shift in the windows vs the cluster center segments.  To account for this, use Dynamic Time Warping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Energy\n",
    "k = 6\n",
    "E = energy_windows\n",
    "km_e = TimeSeriesKMeans(n_clusters=k, metric=\"softdtw\", max_iter=50,\n",
    "                         max_iter_barycenter=5,\n",
    "                         random_state=0).fit(E)\n",
    "#print(km_e.cluster_centers_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed energy windows into kmeans model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = km_e.predict(E)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see which are correct\n",
    "scores = (labels == predict)\n",
    "#combining labeled and predicted cluster scores\n",
    "actual_predicted = np.hstack([labels[:, np.newaxis], predict[:, np.newaxis],scores[:, np.newaxis]])\n",
    "# #print(actual_predicted[0][2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute overall model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual_predicted_ts[i][2]\n",
    "model_accuracy = (sum(scores)/len(scores)) *100\n",
    "print(model_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group model prediction for each cluster per activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_list = ['jog', 'dws', 'wlk','std','ups','sit']\n",
    "\n",
    "print(\"AX cluster scores\")\n",
    "for act in activities_list:\n",
    "    print(act)\n",
    "    predictE = km_e.predict(E[activity_splits[act]])\n",
    "    print(predictE)\n",
    "    print('-----') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for act in activities_list:\n",
    "     predictE = km_e.predict(E[activity_splits[act]])\n",
    "     if act == 'jog':\n",
    "          jog_predict = np.array(predictE)\n",
    "     if act == 'dws':\n",
    "         dws_predict = np.array(predictE)\n",
    "     if act == 'wlk':\n",
    "         wlk_predict = np.array(predictE)\n",
    "     if act == 'std':\n",
    "         std_predict = np.array(predictE)\n",
    "     if act == 'ups':\n",
    "        ups_predict = np.array(predictE)\n",
    "     if act == 'sit':\n",
    "        sit_predict = np.array(predictE)\n",
    "        \n",
    "print(len(jog_predict))     \n",
    "print(len(jog_label))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = np.arange(0,415,1)\n",
    "activityline_dict = {0:'jog begin', 1:'dws begin', 2: 'walk begin', 3:'std begin', 4: 'ups begin', 5: 'sit begin'}\n",
    "activity_colorlabel_dict = {0:'orange', 1:'b', 2: 'k', 3:'c', 4: 'y', 5: 'm'}\n",
    "activitylabel_dict = {0:'dws', 1:'jog', 2: 'wlk ', 3:'N/A', 4: 'walk ', 5: 'std / sit '}\n",
    "\n",
    "\n",
    "activitystart_dict = {0:0, 1: 43, 2: 77, 3:151, 4: 236, 5: 278}\n",
    "k = 6\n",
    "\n",
    "scores_list = scores.tolist()\n",
    "scores_list_len = len(scores_list)\n",
    "score_colors = []\n",
    "\n",
    "for j in range(scores_list_len):\n",
    "    if scores[j] == 0:\n",
    "      score_colors+= [\"red\"]\n",
    "    if scores[j] == 1:\n",
    "         score_colors+= [\"green\"]\n",
    "\n",
    "score_colors = np.asarray(score_colors)\n",
    "score_colors_dict = dict(zip(window, score_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "   plt.axvline(x = activitystart_dict[i], color = 'b', label = activityline_dict[i])\n",
    "\n",
    "for j in range(scores_list_len):\n",
    "   plt.scatter(window[j],scores[j],color = score_colors_dict[j],alpha = .5)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [30,6]\n",
    "plt.legend()\n",
    "plt.title('Label Prediction Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize actual vs predicted activity for each windo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedlabels_colors = []\n",
    "actuallabels_colors = []\n",
    "for j in range(scores_list_len):\n",
    "    if labels[j] == 0:\n",
    "      actuallabels_colors+= ['orange']\n",
    "    if labels[j] == 1:\n",
    "        actuallabels_colors+= ['b']\n",
    "    if labels[j] == 2:\n",
    "        actuallabels_colors+= ['k']\n",
    "    if labels[j] == 3:\n",
    "         actuallabels_colors+= ['c']\n",
    "    if labels[j] == 4:\n",
    "         actuallabels_colors+= ['y']\n",
    "    if labels[j] == 5:\n",
    "         actuallabels_colors+= ['m']\n",
    "\n",
    "    for r in range(scores_list_len):\n",
    "        if predict[r] == 0:\n",
    "            predictedlabels_colors += ['orange']\n",
    "        if predict[r] == 1:\n",
    "            predictedlabels_colors += ['b']\n",
    "        if predict[r] == 2:\n",
    "            predictedlabels_colors += ['k']\n",
    "        if predict[r] == 3:\n",
    "            predictedlabels_colors += ['c']\n",
    "        if predict[r] == 4:\n",
    "            predictedlabels_colors += ['y']\n",
    "        if predict[r] == 5:\n",
    "            predictedlabels_colors += ['m']\n",
    "\n",
    "\n",
    "actuallabels_colors = np.asarray(actuallabels_colors)\n",
    "actuallabels_colors_dict = dict(zip(window, actuallabels_colors))\n",
    "\n",
    "predictedlabels_colors = np.asarray( predictedlabels_colors)\n",
    "predictedlabels_colors_dict = dict(zip(window,  predictedlabels_colors))\n",
    "print(predictedlabels_colors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, sharex ='col')\n",
    "\n",
    "for i in range(k):\n",
    "   axs[0].axvline(x = activitystart_dict[i], color = 'b')\n",
    "   axs[0].scatter(x = 0,y=0, color = activity_colorlabel_dict[i], label = activitylabel_dict[i])\n",
    "   axs[0].legend()\n",
    "\n",
    "for j in range(scores_list_len):\n",
    "    axs[0].scatter(window[j],labels[j],color = actuallabels_colors_dict[j],alpha = .5)\n",
    "\n",
    "axs[0].set_ylabel('Actual \\n Labels')\n",
    "axs[0].set_xlabel('Window')\n",
    "\n",
    "\n",
    "for i in range(k):\n",
    "   axs[1].axvline(x = activitystart_dict[i], color = 'b', label = activityline_dict[i])\n",
    "   axs[1].legend()\n",
    "\n",
    "for j in range(scores_list_len):\n",
    "    axs[1].scatter(window[j],predict[j],color = predictedlabels_colors_dict[j],alpha = .5)\n",
    "axs[1].set_ylabel('Predicted \\n Labels')\n",
    "axs[1].set_xlabel('Window')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute accuracy per activity & visualize in a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('jog predict mode:', stats.mode(jog_predict), (stats.mode(jog_predict)[1][0]/len(jog_predict)*100))\n",
    "print('dws predict mode:', stats.mode(dws_predict), (stats.mode(dws_predict)[1][0]/len(dws_predict))*100)\n",
    "print('wlk predict mode:', stats.mode(wlk_predict), (stats.mode(wlk_predict)[1][0]/len(wlk_predict))*100)\n",
    "print('std predict mode:', stats.mode(std_predict), (stats.mode(std_predict)[1][0]/len(std_predict))*100)\n",
    "print('ups predict mode:', stats.mode(ups_predict), (stats.mode(ups_predict)[1][0]/len(ups_predict))*100)\n",
    "print('sit predict mode:', stats.mode(sit_predict), (stats.mode(sit_predict)[1][0]/len(sit_predict))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
